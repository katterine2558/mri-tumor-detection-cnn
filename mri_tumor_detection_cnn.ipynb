{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNUW1UAw8QtO6+BIdugcHbs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/katterine2558/mri-tumor-detection-cnn/blob/main/mri_tumor_detection_cnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MRI Tumor Detection\n",
        "\n",
        "Este notebook tiene como objetivo desarrollar y evaluar un modelo de red neuronal convolucional (CNN) para la detecci√≥n de tumores cerebrales en im√°genes de resonancia magn√©tica (MRI).\n",
        "El proyecto busca aplicar t√©cnicas de procesamiento de im√°genes m√©dicas y aprendizaje profundo para clasificar las im√°genes en diferentes tipos de tumores, contribuyendo as√≠ al apoyo del diagn√≥stico m√©dico asistido por inteligencia artificial.\n",
        "\n",
        "Se incluyen etapas de preprocesamiento de datos, dise√±o del modelo, entrenamiento y validaci√≥n, as√≠ como el an√°lisis de m√©tricas y visualizaciones que permitan interpretar el desempe√±o del modelo.\n"
      ],
      "metadata": {
        "id": "0OR1YOwmYHAD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Configuraci√≥n de entorno (Colab/GPU)\n",
        "\n",
        "En esta secci√≥n se realiza la configuraci√≥n inicial del entorno de ejecuci√≥n para optimizar el entrenamiento del modelo dentro de Google Colab Pro.\n",
        "El objetivo es garantizar que los recursos de hardware (GPU y memoria) se utilicen de forma eficiente, lo que permite acelerar significativamente los c√°lculos durante el entrenamiento de la red neuronal.\n",
        "\n",
        "Primero, se limpia la sesi√≥n anterior para liberar memoria y evitar conflictos con modelos previamente cargados.\n",
        "Luego, se verifica la disponibilidad de una GPU y se fuerza su uso mediante TensorFlow, configurando adem√°s el crecimiento din√°mico de memoria para prevenir errores por saturaci√≥n.\n",
        "\n",
        "Finalmente, se activa el entrenamiento de precisi√≥n mixta (mixed precision), una t√©cnica que combina c√°lculos en float16 y float32 para mejorar la velocidad sin afectar la precisi√≥n del modelo.\n",
        "Con esta configuraci√≥n, el entorno queda preparado para trabajar con el m√°ximo rendimiento disponible."
      ],
      "metadata": {
        "id": "sKumbUJ4ZVGa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================================\n",
        "# CONFIGURACI√ìN DE ENTORNO COLAB PRO (GPU + OPTIMIZACIONES)\n",
        "# ==========================================================\n",
        "import os, gc, psutil, tensorflow as tf\n",
        "from tensorflow.keras import mixed_precision\n",
        "\n",
        "#Limpiza sesi√≥n anterior\n",
        "gc.collect()\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "#Informaci√≥n del hardware\n",
        "try:\n",
        "    gpu_info = !nvidia-smi --query-gpu=name,memory.total --format=csv,noheader\n",
        "    print(\"GPU detectada:\", gpu_info[0])\n",
        "except:\n",
        "    print(\"No se detect√≥ GPU, verifica que el acelerador est√© activado en Entorno > Configuraci√≥n de ejecuci√≥n.\")\n",
        "\n",
        "#Forzar uso de GPU\n",
        "physical_gpus = tf.config.list_physical_devices('GPU')\n",
        "if physical_gpus:\n",
        "    print(f\"TensorFlow detecta {len(physical_gpus)} GPU(s): {physical_gpus}\")\n",
        "    try:\n",
        "        for gpu in physical_gpus:\n",
        "            tf.config.experimental.set_memory_growth(gpu, True)\n",
        "    except:\n",
        "        pass\n",
        "else:\n",
        "    print(\"No hay GPU activa, se usar√° CPU (entrenamiento m√°s lento).\")\n",
        "\n",
        "#Precisi√≥n mixta para iniciar el entrenamiento\n",
        "mixed_precision.set_global_policy('mixed_float16')\n",
        "tf.debugging.set_log_device_placement(False)\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
        "print(\"Pol√≠tica de precisi√≥n:\", mixed_precision.global_policy())\n",
        "\n",
        "#Informaci√≥n de recursos\n",
        "print(f\"Memoria RAM disponible: {psutil.virtual_memory().total / 1e9:.2f} GB\")\n",
        "print(\"Entorno configurado correctamente para m√°ximo rendimiento.\\n\")"
      ],
      "metadata": {
        "id": "KmvtUb7v10FA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importaci√≥n de librer√≠as y configuraci√≥n inicial\n",
        "\n",
        "En esta secci√≥n se importan todas las librer√≠as necesarias para el desarrollo del proyecto de detecci√≥n de tumores cerebrales mediante im√°genes de resonancia magn√©tica (MRI).\n",
        "Estas librer√≠as permiten realizar tareas de procesamiento de im√°genes, manipulaci√≥n de datos, construcci√≥n del modelo, entrenamiento y evaluaci√≥n de resultados.\n",
        "Adem√°s, se establecen par√°metros base como las rutas de trabajo (`base_dir` y `split_dir`), el tama√±o de lote (`batch_size`), el tama√±o de las im√°genes (`image_size`) y la semilla aleatoria (`seed`) para garantizar la reproducibilidad de los resultados. Finalmente, se verifica la disponibilidad del dispositivo GPU, se activa la pol√≠tica de precisi√≥n mixta y se ajustan las configuraciones del entorno para optimizar el rendimiento durante el entrenamiento del modelo."
      ],
      "metadata": {
        "id": "ASgeevESZ5mY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#==========================================================\n",
        "# LIBRER√çAS\n",
        "#==========================================================\n",
        "from google.colab import files\n",
        "#!pip install -q kaggle #Descomentar si no est√° instalado Kaggle en el entorno\n",
        "import os\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "import shutil\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Input, Dense, Conv2D, MaxPooling2D, Add, Activation,GlobalAveragePooling2D , Multiply, Reshape, DepthwiseConv2D, BatchNormalization ,GlobalAveragePooling2D, Resizing, Rescaling, RandomBrightness, RandomContrast, RandomRotation, RandomZoom, BatchNormalization, Dropout\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.optimizers import Adam, AdamW\n",
        "from tensorflow.keras.initializers import HeNormal\n",
        "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
        "from tensorflow.keras.metrics import AUC\n",
        "!pip install keras-tuner --upgrade\n",
        "from keras_tuner.tuners import RandomSearch\n",
        "from tensorflow.keras import mixed_precision\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import roc_auc_score, roc_curve, auc\n",
        "from sklearn.preprocessing import label_binarize\n",
        "import json\n",
        "!nvidia-smi\n",
        "\n",
        "#==========================================================\n",
        "# CONFIGURACI√ìN INICIAL\n",
        "#==========================================================\n",
        "\n",
        "#Ruta base\n",
        "base_dir = '/content/mri_data'\n",
        "#Ruta para almacenar split\n",
        "split_dir = \"/content/mri_data_split\"\n",
        "#Semilla\n",
        "seed = 0;\n",
        "#Tama√±o del batch\n",
        "batch_size = 16\n",
        "#Image size\n",
        "image_size = (260, 260)\n"
      ],
      "metadata": {
        "id": "GBZzywFcr1rD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Descarga dataset\n",
        "Se descarga el dataset de MRI cerebrales desde Kaggle mediante la API, organizando las im√°genes por categor√≠a.\n",
        "Luego, se listan las clases disponibles y se muestran ejemplos representativos para una inspecci√≥n visual inicial."
      ],
      "metadata": {
        "id": "8uzV1yC9foJI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#==========================================================\n",
        "# DOWNLOAD DATASET\n",
        "#==========================================================\n",
        "def download_mri_data(base_dir:str):\n",
        "\n",
        "  files.upload() #APIKey de Kaggle\n",
        "\n",
        "  !mkdir -p ~/.kaggle\n",
        "  !mv kaggle.json ~/.kaggle/\n",
        "  !chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "  # Descargar el dataset\n",
        "  !mkdir -p /content/mri_data\n",
        "  !kaggle datasets download -d rm1000/brain-tumor-mri-scans -p /content/mri_data --unzip\n",
        "\n",
        "  # Listar categor√≠as\n",
        "  categories = os.listdir(base_dir)\n",
        "  print(\"Categor√≠as encontradas:\", categories)\n",
        "\n",
        "  # Crear grilla 3x4: 3 muestras aleatorias por cada clase (una columna por clase)\n",
        "  n_rows = 3\n",
        "  n_cols = len(categories)\n",
        "  fig, axes = plt.subplots(n_rows, n_cols, figsize=(4*n_cols, 4*n_rows))\n",
        "\n",
        "  for j, c in enumerate(categories):\n",
        "      folder = os.path.join(base_dir, c)\n",
        "      img_list = os.listdir(folder)\n",
        "      for i in range(n_rows):\n",
        "          # Selecciona una imagen aleatoria de la clase\n",
        "          img_name = random.choice(img_list)\n",
        "          img_path = os.path.join(folder, img_name)\n",
        "          img = cv2.imread(img_path)\n",
        "          if img is None:\n",
        "              continue\n",
        "          img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "          ax = axes[i, j]\n",
        "          ax.imshow(img)\n",
        "          if i == 0:  # Solo la primera fila lleva el t√≠tulo\n",
        "              ax.set_title(c.capitalize(), fontsize=12, fontweight='bold')\n",
        "          ax.axis('off')\n",
        "\n",
        "  plt.tight_layout()\n",
        "  plt.show()\n",
        "\n",
        "#Descarga el conjunto de datos y visualiza\n",
        "download_mri_data(base_dir)"
      ],
      "metadata": {
        "id": "JQOc_LcWsUpH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## An√°lisis exploratorio y preprocesamiento de im√°genes\n",
        "\n",
        "### Distribuci√≥n de clases\n",
        "\n",
        "En esta etapa se analiza la distribuci√≥n del n√∫mero de im√°genes por clase dentro del conjunto de datos.\n",
        "Este gr√°fico de barras permite identificar posibles desequilibrios entre categor√≠as, lo cual es importante antes de entrenar el modelo, ya que una distribuci√≥n desigual podr√≠a afectar el desempe√±o y la generalizaci√≥n de la red neuronal."
      ],
      "metadata": {
        "id": "eZLm9CBAg_Fc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================================\n",
        "# DISTRIBUCI√ìN DE CLASES\n",
        "# ==========================================================\n",
        "def plot_class_distribution(base_dir: str):\n",
        "\n",
        "    class_counts = {}\n",
        "\n",
        "    # Recorre cada carpeta (clase)\n",
        "    for cls in sorted(os.listdir(base_dir)):\n",
        "        cls_path = os.path.join(base_dir, cls)\n",
        "        if not os.path.isdir(cls_path):\n",
        "            continue\n",
        "        n_images = len([\n",
        "            f for f in os.listdir(cls_path)\n",
        "            if f.lower().endswith(('.png', '.jpg', '.jpeg'))\n",
        "        ])\n",
        "        class_counts[cls] = n_images\n",
        "\n",
        "    # --- Gr√°fico de barras ---\n",
        "    plt.figure(figsize=(6,4))\n",
        "    bars = plt.bar(class_counts.keys(), class_counts.values(), color=\"#828282\")\n",
        "    plt.xlabel(\"Clase\")\n",
        "    plt.ylabel(\"N√∫mero de im√°genes\")\n",
        "    plt.xticks(rotation=15)\n",
        "    plt.ylim(0,2200)\n",
        "\n",
        "    # Etiquetas encima de cada barra\n",
        "    for bar in bars:\n",
        "        yval = bar.get_height()\n",
        "        plt.text(bar.get_x() + bar.get_width()/2, yval + 20, str(yval),\n",
        "                 ha='center', va='bottom', fontsize=9)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    return class_counts\n",
        "\n",
        "# Ejecutar funci√≥n\n",
        "plot_class_distribution(base_dir)\n"
      ],
      "metadata": {
        "id": "fE8eqMpakpPi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exploraci√≥n de resoluciones en las im√°genes\n",
        "\n",
        "En esta secci√≥n se analizan las dimensiones (ancho y alto) de las im√°genes del conjunto de datos.\n",
        "Los histogramas permiten observar la variabilidad en las resoluciones originales, lo que ayuda a determinar la necesidad de aplicar un redimensionamiento uniforme antes del entrenamiento del modelo y asegurar una entrada consistente a la red neuronal."
      ],
      "metadata": {
        "id": "H1Vd2Ngzl9as"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================================\n",
        "# HISTOGRAMAS DE ANCHOS Y ALTOS DE LAS IM√ÅGENES\n",
        "# ==========================================================\n",
        "def plot_image_size_distribution(base_dir: str, sample_per_class: int = 1000):\n",
        "    \"\"\"\n",
        "    Calcula y grafica la distribuci√≥n de anchos y altos de las im√°genes\n",
        "    muestreando hasta sample_per_class por clase.\n",
        "    \"\"\"\n",
        "    widths, heights = [], []\n",
        "\n",
        "    for cls in sorted(os.listdir(base_dir)):\n",
        "        cls_path = os.path.join(base_dir, cls)\n",
        "        if not os.path.isdir(cls_path):\n",
        "            continue\n",
        "\n",
        "        # limitar muestras por clase (para rapidez)\n",
        "        img_files = [\n",
        "            f for f in os.listdir(cls_path)\n",
        "            if f.lower().endswith(('.png', '.jpg', '.jpeg'))\n",
        "        ][:sample_per_class]\n",
        "\n",
        "        for fname in img_files:\n",
        "            img_path = os.path.join(cls_path, fname)\n",
        "            img = cv2.imread(img_path)\n",
        "            if img is None:\n",
        "                continue\n",
        "            h, w = img.shape[:2]\n",
        "            widths.append(w)\n",
        "            heights.append(h)\n",
        "\n",
        "    # --- Estad√≠sticas ---\n",
        "    print(f\"Total de im√°genes analizadas: {len(widths)}\")\n",
        "    print(f\"‚Ä¢ Ancho promedio:  {np.mean(widths):.1f}px | Rango: {min(widths)}‚Äì{max(widths)}\")\n",
        "    print(f\"‚Ä¢ Alto  promedio:  {np.mean(heights):.1f}px | Rango: {min(heights)}‚Äì{max(heights)}\")\n",
        "\n",
        "    # --- Subplots ---\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(10, 4))\n",
        "\n",
        "    axes[0].hist(widths, bins=20, color=\"#4B9CD3\", edgecolor='black', alpha=0.8)\n",
        "    axes[0].set_title(\"a) Distribuci√≥n de anchos\")\n",
        "    axes[0].set_xlabel(\"Ancho (px)\")\n",
        "    axes[0].set_ylabel(\"Frecuencia\")\n",
        "\n",
        "    axes[1].hist(heights, bins=20, color=\"#E69138\", edgecolor='black', alpha=0.8)\n",
        "    axes[1].set_title(\"b) Distribuci√≥n de altos\")\n",
        "    axes[1].set_xlabel(\"Alto (px)\")\n",
        "    axes[1].set_ylabel(\"Frecuencia\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Ejecutar funci√≥n\n",
        "plot_image_size_distribution(base_dir)\n"
      ],
      "metadata": {
        "id": "w4WaSOEMmBHP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualizaci√≥n de Data Augmentation\n",
        "\n",
        "En esta secci√≥n se muestran ejemplos ilustrativos de las transformaciones de data augmentation implementadas dentro del modelo.\n",
        "Estas operaciones ‚Äîcomo volteo horizontal, rotaci√≥n, zoom y ajuste de contraste‚Äî permiten aumentar la variabilidad del conjunto de entrenamiento, ayudando al modelo a generalizar mejor y evitar el sobreajuste."
      ],
      "metadata": {
        "id": "Ep3qjRvOovoh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================================\n",
        "# VISUALIZACI√ìN DEL DATA AUGMENTATION (EJEMPLOS ILUSTRATIVOS)\n",
        "# ==========================================================\n",
        "def visualize_data_augmentation(base_dir: str, image_size=(224,224)):\n",
        "    \"\"\"\n",
        "    Muestra una grilla con una imagen original y las transformaciones de\n",
        "    data augmentation aplicadas (flip, rotaci√≥n, zoom, contraste)\n",
        "    para cada clase.\n",
        "    \"\"\"\n",
        "\n",
        "    # Capas de augmentaci√≥n (id√©nticas a las del modelo)\n",
        "    aug_flip = tf.keras.layers.RandomFlip(\"horizontal\")\n",
        "    aug_rotation = tf.keras.layers.RandomRotation(0.08)\n",
        "    aug_zoom = tf.keras.layers.RandomZoom(0.1)\n",
        "    aug_contrast = tf.keras.layers.RandomContrast(0.2)\n",
        "\n",
        "    transformations = [\n",
        "        (\"Original\", lambda x: x),\n",
        "        (\"Flip\", aug_flip),\n",
        "        (\"Rotaci√≥n\", aug_rotation),\n",
        "        (\"Zoom\", aug_zoom),\n",
        "        (\"Contraste\", aug_contrast),\n",
        "    ]\n",
        "\n",
        "    # Clases ordenadas\n",
        "    class_names = sorted([\n",
        "        d for d in os.listdir(base_dir)\n",
        "        if os.path.isdir(os.path.join(base_dir, d))\n",
        "    ])\n",
        "\n",
        "    n_rows = len(class_names)\n",
        "    n_cols = len(transformations)\n",
        "\n",
        "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(3.5*n_cols, 3.5*n_rows))\n",
        "    if n_rows == 1:\n",
        "        axes = np.expand_dims(axes, axis=0)  # asegura 2D\n",
        "\n",
        "    for i, cls in enumerate(class_names):\n",
        "        # Seleccionar una imagen aleatoria\n",
        "        cls_path = os.path.join(base_dir, cls)\n",
        "        candidates = [f for f in os.listdir(cls_path) if f.lower().endswith(('.png','.jpg','.jpeg'))]\n",
        "        if not candidates:\n",
        "            continue\n",
        "        img_path = os.path.join(cls_path, random.choice(candidates))\n",
        "\n",
        "        # Cargar y preparar la imagen\n",
        "        img = tf.keras.utils.load_img(img_path, target_size=image_size)\n",
        "        img_array = tf.keras.utils.img_to_array(img)\n",
        "        img_array = np.array(img_array, dtype=np.float32) / 255.0\n",
        "        img_batch = tf.expand_dims(img_array, 0)\n",
        "\n",
        "        for j, (name, transform) in enumerate(transformations):\n",
        "            ax = axes[i, j]\n",
        "            if name == \"Original\":\n",
        "                aug_img = img_array\n",
        "            else:\n",
        "                aug_img = transform(img_batch, training=True)[0].numpy().astype(np.float32)\n",
        "\n",
        "            ax.imshow(np.clip(aug_img, 0, 1))\n",
        "            if i == 0:\n",
        "                ax.set_title(name, fontsize=12, fontweight='bold')\n",
        "            if j == 0:\n",
        "                ax.set_ylabel(cls.capitalize(), fontsize=12, rotation=0, labelpad=60)\n",
        "            ax.axis(\"off\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Ejecutar\n",
        "visualize_data_augmentation(base_dir, image_size=(image_size[0], image_size[1]))"
      ],
      "metadata": {
        "id": "uDvO1Exeyn1r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================================\n",
        "# TRAIN-VAL-TEST DIVISION (70-20-10)\n",
        "# ==========================================================\n",
        "def traint_val_test_split(base_dir:str, split_dir:str):\n",
        "    # Crear carpetas destino\n",
        "    for split in ['train', 'val', 'test']:\n",
        "        for cls in os.listdir(base_dir):\n",
        "            os.makedirs(os.path.join(split_dir, split, cls), exist_ok=True)\n",
        "\n",
        "    # Ratios\n",
        "    train_ratio = 0.7\n",
        "    val_ratio = 0.2\n",
        "    test_ratio = 0.1\n",
        "\n",
        "    # Procesar cada clase\n",
        "    for cls in os.listdir(base_dir):\n",
        "        cls_path = os.path.join(base_dir, cls)\n",
        "        images = [f for f in os.listdir(cls_path) if f.lower().endswith(('.png','.jpg','.jpeg'))]\n",
        "\n",
        "        # Dividir train / val / test\n",
        "        train_files, temp_files = train_test_split(images, test_size=(1-train_ratio), random_state=seed)\n",
        "        val_size = val_ratio / (val_ratio + test_ratio)\n",
        "        val_files, test_files = train_test_split(temp_files, test_size=(1-val_size), random_state=seed)\n",
        "\n",
        "        # Copiar archivos\n",
        "        for fname in train_files:\n",
        "            shutil.copy(os.path.join(cls_path, fname), os.path.join(split_dir, 'train', cls, fname))\n",
        "        for fname in val_files:\n",
        "            shutil.copy(os.path.join(cls_path, fname), os.path.join(split_dir, 'val', cls, fname))\n",
        "        for fname in test_files:\n",
        "            shutil.copy(os.path.join(cls_path, fname), os.path.join(split_dir, 'test', cls, fname))\n",
        "\n",
        "    print(\"Divisi√≥n completada con semilla =\", seed)\n",
        "    print(\"Estructura creada en:\", split_dir)\n",
        "\n",
        "    for split in ['train', 'val', 'test']:\n",
        "        print(f\"\\n * {split.upper()}\")\n",
        "        for cls in os.listdir(os.path.join(split_dir, split)):\n",
        "            count = len(os.listdir(os.path.join(split_dir, split, cls)))\n",
        "            print(f\"  {cls}: {count} im√°genes\")\n",
        "\n",
        "\n",
        "# Ejecutar divisi√≥n solo una vez\n",
        "traint_val_test_split(base_dir, split_dir)\n",
        "\n",
        "# ==========================================================\n",
        "# CARGA DE LOS DATASETS\n",
        "# ==========================================================\n",
        "train_ds_raw = tf.keras.utils.image_dataset_from_directory(\n",
        "    f\"{split_dir}/train\",\n",
        "    image_size=image_size,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    seed=seed\n",
        ")\n",
        "\n",
        "val_ds_raw = tf.keras.utils.image_dataset_from_directory(\n",
        "    f\"{split_dir}/val\",\n",
        "    image_size=image_size,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    seed=seed\n",
        ")\n",
        "\n",
        "test_ds_raw = tf.keras.utils.image_dataset_from_directory(\n",
        "    f\"{split_dir}/test\",\n",
        "    image_size=image_size,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,\n",
        "    seed=seed\n",
        ")\n",
        "\n",
        "# Guarda los nombres de clase ANTES de optimizar los datasets\n",
        "class_names = test_ds_raw.class_names\n",
        "print(\"Clases detectadas:\", class_names)\n",
        "\n",
        "# ==========================================================\n",
        "# OPTIMIZACI√ìN DE LOS DATASETS\n",
        "# ==========================================================\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "def prepare_dataset(ds, shuffle=False):\n",
        "    if shuffle:\n",
        "        ds = ds.shuffle(buffer_size=1000)\n",
        "    ds = ds.prefetch(AUTOTUNE)\n",
        "    return ds\n",
        "\n",
        "train_ds = prepare_dataset(train_ds_raw, shuffle=True)\n",
        "val_ds   = prepare_dataset(val_ds_raw)\n",
        "test_ds  = prepare_dataset(test_ds_raw)\n",
        "\n",
        "print(\"Datasets listos y optimizados para entrenamiento.\")"
      ],
      "metadata": {
        "id": "cEMADKmdWuvX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hLR5Mm83cO1W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================================\n",
        "# ACTIVACI√ìN MISH\n",
        "# ==========================================================\n",
        "@tf.keras.utils.register_keras_serializable()\n",
        "def mish(x):\n",
        "    return x * tf.math.tanh(tf.math.softplus(x))\n",
        "\n",
        "\n",
        "# ==========================================================\n",
        "# BLOQUE MBConv MEJORADO (con DropConnect)\n",
        "# ==========================================================\n",
        "def MBConvMRI(inputs, out_channels, expand_ratio, stride, se_ratio=0.25, drop_rate=0.2):\n",
        "    in_channels = inputs.shape[-1]\n",
        "    shortcut = inputs\n",
        "    x = inputs\n",
        "\n",
        "    expanded = int(in_channels * expand_ratio)\n",
        "    if expand_ratio != 1:\n",
        "        x = layers.Conv2D(expanded, 1, padding='same', use_bias=False, kernel_initializer=HeNormal())(x)\n",
        "        x = layers.BatchNormalization()(x)\n",
        "        x = layers.Activation(mish)(x)\n",
        "\n",
        "    # Depthwise separable\n",
        "    x = layers.DepthwiseConv2D(3, strides=stride, padding='same', use_bias=False)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation(mish)(x)\n",
        "\n",
        "    # Squeeze and Excitation\n",
        "    se = layers.GlobalAveragePooling2D()(x)\n",
        "    se = layers.Reshape((1,1,expanded))(se)\n",
        "    se = layers.Conv2D(int(expanded * se_ratio), 1, activation=mish, padding='same')(se)\n",
        "    se = layers.Conv2D(expanded, 1, activation='sigmoid', padding='same')(se)\n",
        "    x = layers.Multiply()([x, se])\n",
        "\n",
        "    # Proyecci√≥n\n",
        "    x = layers.Conv2D(out_channels, 1, padding='same', use_bias=False, kernel_initializer=HeNormal())(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "\n",
        "    # Residual con DropConnect\n",
        "    if stride == 1 and in_channels == out_channels:\n",
        "        if drop_rate > 0:\n",
        "            x = layers.Dropout(drop_rate)(x)\n",
        "        x = layers.Add()([x, shortcut])\n",
        "    return x\n",
        "\n",
        "\n",
        "# ==========================================================\n",
        "# MODELO EfficientMRI-Net v2\n",
        "# ==========================================================\n",
        "def build_efficient_mri_net_v2(num_classes=4, input_shape=(image_size[0], image_size[1], 3)):\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "\n",
        "    # -----------------------------\n",
        "    # Data augmentation integrado\n",
        "    # -----------------------------\n",
        "    x = layers.RandomFlip(\"horizontal\")(inputs)\n",
        "    x = layers.RandomRotation(0.08)(x)\n",
        "    x = layers.RandomZoom(0.1)(x)\n",
        "    x = layers.RandomContrast(0.2)(x)\n",
        "    x = layers.Rescaling(1./255)(x)\n",
        "\n",
        "    # -----------------------------\n",
        "    # Bloque inicial\n",
        "    # -----------------------------\n",
        "    x = layers.Conv2D(48, 3, strides=2, padding='same', use_bias=False, kernel_initializer=HeNormal())(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation(mish)(x)\n",
        "\n",
        "    # -----------------------------\n",
        "    # Bloques MBConv\n",
        "    # -----------------------------\n",
        "    x = MBConvMRI(x, 16, 1, 1, drop_rate=0.1)\n",
        "    x = MBConvMRI(x, 24, 3, 2, drop_rate=0.1)\n",
        "    x = MBConvMRI(x, 24, 3, 1, drop_rate=0.1)\n",
        "    x = MBConvMRI(x, 40, 4, 2, drop_rate=0.15)\n",
        "    x = MBConvMRI(x, 40, 4, 1, drop_rate=0.15)\n",
        "    x = MBConvMRI(x, 80, 4, 2, drop_rate=0.2)\n",
        "    x = MBConvMRI(x, 80, 4, 1, drop_rate=0.2)\n",
        "    x = MBConvMRI(x, 112, 4, 1, drop_rate=0.25)\n",
        "    x = MBConvMRI(x, 160, 4, 2, drop_rate=0.25)\n",
        "    x = MBConvMRI(x, 320, 4, 1, drop_rate=0.3)\n",
        "\n",
        "    # -----------------------------\n",
        "    # Head final\n",
        "    # -----------------------------\n",
        "    x = layers.Conv2D(1280, 1, padding='same', use_bias=False, kernel_initializer=HeNormal())(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation(mish)(x)\n",
        "\n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "    x = layers.Dropout(0.4)(x)\n",
        "    outputs = layers.Dense(num_classes, activation='softmax', dtype='float32')(x)\n",
        "\n",
        "    model = Model(inputs, outputs, name=\"EfficientMRI_Net_v2\")\n",
        "    return model\n",
        "\n",
        "\n",
        "# ==========================================================\n",
        "# COMPILACI√ìN\n",
        "# ==========================================================\n",
        "model = build_efficient_mri_net_v2(num_classes=4, input_shape=(image_size[0], image_size[1],3))\n",
        "optimizer = AdamW(learning_rate=8e-4, weight_decay=1e-5)\n",
        "loss_fn = SparseCategoricalCrossentropy()\n",
        "\n",
        "model.compile(\n",
        "    optimizer=optimizer,\n",
        "    loss=loss_fn,\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# ==========================================================\n",
        "# CALLBACKS\n",
        "# ==========================================================\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.6, patience=5, min_lr=1e-5, verbose=1)\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=6, restore_best_weights=True, verbose=1)\n",
        "checkpoint = ModelCheckpoint('EfficientMRI_Net_v2.keras', monitor='val_accuracy', save_best_only=True, verbose=1)\n",
        "\n",
        "model.summary()\n",
        "\n",
        "\n",
        "# ==========================================================\n",
        "# ENTRENAMIENTO O CARGA DEL MODELO\n",
        "# ==========================================================\n",
        "history = None\n",
        "\n",
        "if os.path.exists('EfficientMRI_Net_v2.keras'):\n",
        "    print(\"Cargando modelo desde el checkpoint...\")\n",
        "    model.load_weights('EfficientMRI_Net_v2.keras')\n",
        "    print(\"Pesos cargados correctamente.\")\n",
        "else:\n",
        "    print(\"Iniciando entrenamiento desde cero...\")\n",
        "    history = model.fit(\n",
        "        train_ds,\n",
        "        validation_data=val_ds,\n",
        "        epochs=80,\n",
        "        batch_size=batch_size,\n",
        "        callbacks=[reduce_lr, early_stop, checkpoint],\n",
        "        verbose=1\n",
        "    )\n"
      ],
      "metadata": {
        "id": "1RFM0cWSMCpZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================================\n",
        "# GGUARDA LA HISTORIA\n",
        "# ==========================================================\n",
        "# Guardar la historia completa como JSON\n",
        "with open('history_efficient_mri_net_v2.json', 'w') as f:\n",
        "        json.dump(history.history, f)\n",
        "\n",
        "# ==========================================================\n",
        "# GR√ÅFICAS DE ENTRENAMIENTO Y VALIDACI√ìN\n",
        "# ==========================================================\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(1, len(acc) + 1)\n",
        "\n",
        "plt.figure(figsize=(14,5))\n",
        "\n",
        "# Accuracy\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, 'b-', label='Entrenamiento')\n",
        "plt.plot(epochs_range, val_acc, 'r--', label='Validaci√≥n')\n",
        "plt.title('Evoluci√≥n del Accuracy')\n",
        "plt.xlabel('√âpoca')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.grid(True, linestyle='--', alpha=0.5)\n",
        "\n",
        "# Loss\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, 'b-', label='Entrenamiento')\n",
        "plt.plot(epochs_range, val_loss, 'r--', label='Validaci√≥n')\n",
        "plt.title('Evoluci√≥n de la P√©rdida (Loss)')\n",
        "plt.xlabel('√âpoca')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.grid(True, linestyle='--', alpha=0.5)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ZXCxjlIGswxh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================================\n",
        "# EVALUACI√ìN FINAL EN TEST\n",
        "# ==========================================================\n",
        "test_loss, test_acc = model.evaluate(test_ds, verbose=1)\n",
        "print(f\"\\n‚úÖ Test Accuracy: {test_acc:.4f}\")\n",
        "print(f\"üìâ Test Loss: {test_loss:.4f}\")\n"
      ],
      "metadata": {
        "id": "qyWjcRYaRmUm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================================\n",
        "# REPORTE DE MATRIZ DE CONFUSI√ìN\n",
        "# ==========================================================\n",
        "y_true = np.concatenate([y for x, y in test_ds], axis=0)\n",
        "y_pred_probs = model.predict(test_ds)\n",
        "y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "\n",
        "print(\"\\nüßæ Reporte de Clasificaci√≥n:\\n\")\n",
        "print(classification_report(y_true, y_pred, target_names=class_names, digits=2))\n",
        "\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "plt.figure(figsize=(7,6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=class_names, yticklabels=class_names)\n",
        "plt.title(\"Matriz de Confusi√≥n - EfficientMRI-Net\")\n",
        "plt.xlabel(\"Predicci√≥n\")\n",
        "plt.ylabel(\"Real\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "DCjLoldKSyVW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================================\n",
        "# C√ÅLCULO DE AUC MULTICLASE\n",
        "# ==========================================================\n",
        "# Convertimos las etiquetas verdaderas a formato binarizado (one-hot)\n",
        "y_true_bin = label_binarize(y_true, classes=np.arange(len(class_names)))\n",
        "\n",
        "# AUC por clase y promedio\n",
        "auc_macro = roc_auc_score(y_true_bin, y_pred_probs, multi_class='ovr', average='macro')\n",
        "auc_weighted = roc_auc_score(y_true_bin, y_pred_probs, multi_class='ovr', average='weighted')\n",
        "\n",
        "print(f\"\\nAUC promedio (macro): {auc_macro:.4f}\")\n",
        "print(f\"AUC promedio (ponderado): {auc_weighted:.4f}\\n\")\n",
        "\n",
        "\n",
        "# ==========================================================\n",
        "# CURVAS ROC (opcional, para visualizar por clase)\n",
        "# ==========================================================\n",
        "plt.figure(figsize=(8,6))\n",
        "for i, class_name in enumerate(class_names):\n",
        "    fpr, tpr, _ = roc_curve(y_true_bin[:, i], y_pred_probs[:, i])\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    plt.plot(fpr, tpr, lw=2, label=f'{class_name} (AUC = {roc_auc:.2f})')\n",
        "\n",
        "plt.plot([0, 1], [0, 1], color='gray', lw=2, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('Tasa de Falsos Positivos (FPR)')\n",
        "plt.ylabel('Tasa de Verdaderos Positivos (TPR)')\n",
        "plt.title('Curvas ROC - EfficientMRI-Net')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "fsKlWoqLr7Em"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kFPU7r7PC1Ld"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}