{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPeTxIsq6UpzZ202UMJK73t",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/katterine2558/mri-tumor-detection-cnn/blob/main/mri_tumor_detection_cnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MRI Tumor Detection\n",
        "\n",
        "Este notebook tiene como objetivo desarrollar y evaluar un modelo de red neuronal convolucional (CNN) para la detección de tumores cerebrales en imágenes de resonancia magnética (MRI).\n",
        "\n",
        "El proyecto busca aplicar técnicas de procesamiento de imágenes médicas y aprendizaje profundo para clasificar las imágenes en diferentes tipos de tumores, contribuyendo así al apoyo del diagnóstico médico asistido por inteligencia artificial.\n",
        "\n",
        "Se incluyen etapas de preprocesamiento de datos, diseño del modelo, entrenamiento y validación, así como el análisis de métricas y visualizaciones que permitan interpretar el desempeño del modelo."
      ],
      "metadata": {
        "id": "0OR1YOwmYHAD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Configuración de entorno (Colab/GPU)\n",
        "\n",
        "En esta sección se realiza la configuración inicial del entorno de ejecución para optimizar el entrenamiento del modelo dentro de Google Colab Pro.\n",
        "El objetivo es garantizar que los recursos de hardware (GPU y memoria) se utilicen de forma eficiente, lo que permite acelerar significativamente los cálculos durante el entrenamiento de la red neuronal.\n",
        "\n",
        "Primero, se limpia la sesión anterior para liberar memoria y evitar conflictos con modelos previamente cargados.\n",
        "Luego, se verifica la disponibilidad de una GPU y se fuerza su uso mediante TensorFlow, configurando además el crecimiento dinámico de memoria para prevenir errores por saturación.\n",
        "\n",
        "Finalmente, se activa el entrenamiento de precisión mixta (mixed precision), una técnica que combina cálculos en float16 y float32 para mejorar la velocidad sin afectar la precisión del modelo.\n",
        "Con esta configuración, el entorno queda preparado para trabajar con el máximo rendimiento disponible."
      ],
      "metadata": {
        "id": "sKumbUJ4ZVGa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================================\n",
        "# CONFIGURACIÓN DE ENTORNO COLAB PRO (GPU + OPTIMIZACIONES)\n",
        "# ==========================================================\n",
        "import os, gc, psutil, tensorflow as tf\n",
        "from tensorflow.keras import mixed_precision\n",
        "\n",
        "#Limpiza sesión anterior\n",
        "gc.collect()\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "#Información del hardware\n",
        "try:\n",
        "    gpu_info = !nvidia-smi --query-gpu=name,memory.total --format=csv,noheader\n",
        "    print(\"GPU detectada:\", gpu_info[0])\n",
        "except:\n",
        "    print(\"No se detectó GPU, verifica que el acelerador esté activado en Entorno > Configuración de ejecución.\")\n",
        "\n",
        "#Forzar uso de GPU\n",
        "physical_gpus = tf.config.list_physical_devices('GPU')\n",
        "if physical_gpus:\n",
        "    print(f\"TensorFlow detecta {len(physical_gpus)} GPU(s): {physical_gpus}\")\n",
        "    try:\n",
        "        for gpu in physical_gpus:\n",
        "            tf.config.experimental.set_memory_growth(gpu, True)\n",
        "    except:\n",
        "        pass\n",
        "else:\n",
        "    print(\"No hay GPU activa, se usará CPU (entrenamiento más lento).\")\n",
        "\n",
        "#Precisión mixta para iniciar el entrenamiento\n",
        "mixed_precision.set_global_policy('mixed_float16')\n",
        "tf.debugging.set_log_device_placement(False)\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
        "print(\"Política de precisión:\", mixed_precision.global_policy())\n",
        "\n",
        "#Información de recursos\n",
        "print(f\"Memoria RAM disponible: {psutil.virtual_memory().total / 1e9:.2f} GB\")\n",
        "print(\"Entorno configurado correctamente para máximo rendimiento.\\n\")"
      ],
      "metadata": {
        "id": "KmvtUb7v10FA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importación de librerías y configuración inicial\n",
        "\n",
        "En esta sección se importan todas las librerías necesarias para el desarrollo del proyecto de detección de tumores cerebrales mediante imágenes de resonancia magnética (MRI).\n",
        "Estas librerías permiten realizar tareas de procesamiento de imágenes, manipulación de datos, construcción del modelo, entrenamiento y evaluación de resultados.\n",
        "Además, se establecen parámetros base como las rutas de trabajo (`base_dir` y `split_dir`), el tamaño de lote (`batch_size`), el tamaño de las imágenes (`image_size`) y la semilla aleatoria (`seed`) para garantizar la reproducibilidad de los resultados. Finalmente, se verifica la disponibilidad del dispositivo GPU, se activa la política de precisión mixta y se ajustan las configuraciones del entorno para optimizar el rendimiento durante el entrenamiento del modelo."
      ],
      "metadata": {
        "id": "ASgeevESZ5mY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#==========================================================\n",
        "# LIBRERÍAS\n",
        "#==========================================================\n",
        "from google.colab import files\n",
        "#!pip install -q kaggle #Descomentar si no está instalado Kaggle en el entorno\n",
        "import os\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "import shutil\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Input, Dense, Conv2D, MaxPooling2D, Add, Activation,GlobalAveragePooling2D , Multiply, Reshape, DepthwiseConv2D, BatchNormalization ,GlobalAveragePooling2D, Resizing, Rescaling, RandomBrightness, RandomContrast, RandomRotation, RandomZoom, BatchNormalization, Dropout\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.optimizers import Adam, AdamW\n",
        "from tensorflow.keras.initializers import HeNormal\n",
        "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
        "from tensorflow.keras.metrics import AUC\n",
        "!pip install keras-tuner --upgrade\n",
        "from keras_tuner.tuners import RandomSearch\n",
        "from tensorflow.keras import mixed_precision\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import roc_auc_score, roc_curve, auc\n",
        "from sklearn.preprocessing import label_binarize\n",
        "import json\n",
        "from tensorflow.keras import backend as K\n",
        "!nvidia-smi\n",
        "\n",
        "#==========================================================\n",
        "# CONFIGURACIÓN INICIAL\n",
        "#==========================================================\n",
        "\n",
        "#Ruta base\n",
        "base_dir = '/content/mri_data'\n",
        "#Ruta para almacenar split\n",
        "split_dir = \"/content/mri_data_split\"\n",
        "#Semilla\n",
        "seed = 0;\n",
        "#Tamaño del batch\n",
        "batch_size = 16\n",
        "#Image size\n",
        "image_size = (260, 260)\n"
      ],
      "metadata": {
        "id": "GBZzywFcr1rD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Descarga dataset\n",
        "Se descarga el dataset de MRI cerebrales desde Kaggle mediante la API, organizando las imágenes por categoría.\n",
        "Luego, se listan las clases disponibles y se muestran ejemplos representativos para una inspección visual inicial."
      ],
      "metadata": {
        "id": "8uzV1yC9foJI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#==========================================================\n",
        "# DOWNLOAD DATASET\n",
        "#==========================================================\n",
        "def download_mri_data(base_dir:str):\n",
        "\n",
        "  files.upload() #APIKey de Kaggle\n",
        "\n",
        "  !mkdir -p ~/.kaggle\n",
        "  !mv kaggle.json ~/.kaggle/\n",
        "  !chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "  # Descargar el dataset\n",
        "  !mkdir -p /content/mri_data\n",
        "  !kaggle datasets download -d rm1000/brain-tumor-mri-scans -p /content/mri_data --unzip\n",
        "\n",
        "  # Listar categorías\n",
        "  categories = os.listdir(base_dir)\n",
        "  print(\"Categorías encontradas:\", categories)\n",
        "\n",
        "  # Crear grilla 3x4: 3 muestras aleatorias por cada clase (una columna por clase)\n",
        "  n_rows = 3\n",
        "  n_cols = len(categories)\n",
        "  fig, axes = plt.subplots(n_rows, n_cols, figsize=(4*n_cols, 4*n_rows))\n",
        "\n",
        "  for j, c in enumerate(categories):\n",
        "      folder = os.path.join(base_dir, c)\n",
        "      img_list = os.listdir(folder)\n",
        "      for i in range(n_rows):\n",
        "          # Selecciona una imagen aleatoria de la clase\n",
        "          img_name = random.choice(img_list)\n",
        "          img_path = os.path.join(folder, img_name)\n",
        "          img = cv2.imread(img_path)\n",
        "          if img is None:\n",
        "              continue\n",
        "          img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "          ax = axes[i, j]\n",
        "          ax.imshow(img)\n",
        "          if i == 0:  # Solo la primera fila lleva el título\n",
        "              ax.set_title(c.capitalize(), fontsize=12, fontweight='bold')\n",
        "          ax.axis('off')\n",
        "\n",
        "  plt.tight_layout()\n",
        "  plt.show()\n",
        "\n",
        "#Descarga el conjunto de datos y visualiza\n",
        "download_mri_data(base_dir)"
      ],
      "metadata": {
        "id": "JQOc_LcWsUpH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Análisis exploratorio y preprocesamiento de imágenes\n",
        "\n",
        "### Distribución de clases\n",
        "\n",
        "En esta etapa se analiza la distribución del número de imágenes por clase dentro del conjunto de datos.\n",
        "Este gráfico de barras permite identificar posibles desequilibrios entre categorías, lo cual es importante antes de entrenar el modelo, ya que una distribución desigual podría afectar el desempeño y la generalización de la red neuronal."
      ],
      "metadata": {
        "id": "eZLm9CBAg_Fc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================================\n",
        "# DISTRIBUCIÓN DE CLASES\n",
        "# ==========================================================\n",
        "def plot_class_distribution(base_dir: str):\n",
        "\n",
        "    class_counts = {}\n",
        "\n",
        "    # Recorre cada carpeta (clase)\n",
        "    for cls in sorted(os.listdir(base_dir)):\n",
        "        cls_path = os.path.join(base_dir, cls)\n",
        "        if not os.path.isdir(cls_path):\n",
        "            continue\n",
        "        n_images = len([\n",
        "            f for f in os.listdir(cls_path)\n",
        "            if f.lower().endswith(('.png', '.jpg', '.jpeg'))\n",
        "        ])\n",
        "        class_counts[cls] = n_images\n",
        "\n",
        "    # --- Gráfico de barras ---\n",
        "    plt.figure(figsize=(6,4))\n",
        "    bars = plt.bar(class_counts.keys(), class_counts.values(), color=\"#828282\")\n",
        "    plt.xlabel(\"Clase\")\n",
        "    plt.ylabel(\"Número de imágenes\")\n",
        "    plt.xticks(rotation=15)\n",
        "    plt.ylim(0,2200)\n",
        "\n",
        "    # Etiquetas encima de cada barra\n",
        "    for bar in bars:\n",
        "        yval = bar.get_height()\n",
        "        plt.text(bar.get_x() + bar.get_width()/2, yval + 20, str(yval),\n",
        "                 ha='center', va='bottom', fontsize=9)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    return class_counts\n",
        "\n",
        "# Ejecutar función\n",
        "plot_class_distribution(base_dir)\n"
      ],
      "metadata": {
        "id": "fE8eqMpakpPi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exploración de resoluciones en las imágenes\n",
        "\n",
        "En esta sección se analizan las dimensiones (ancho y alto) de las imágenes del conjunto de datos.\n",
        "Los histogramas permiten observar la variabilidad en las resoluciones originales, lo que ayuda a determinar la necesidad de aplicar un redimensionamiento uniforme antes del entrenamiento del modelo y asegurar una entrada consistente a la red neuronal."
      ],
      "metadata": {
        "id": "H1Vd2Ngzl9as"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================================\n",
        "# HISTOGRAMAS DE ANCHOS Y ALTOS DE LAS IMÁGENES\n",
        "# ==========================================================\n",
        "def plot_image_size_distribution(base_dir: str, sample_per_class: int = 1000):\n",
        "    \"\"\"\n",
        "    Calcula y grafica la distribución de anchos y altos de las imágenes\n",
        "    muestreando hasta sample_per_class por clase.\n",
        "    \"\"\"\n",
        "    widths, heights = [], []\n",
        "\n",
        "    for cls in sorted(os.listdir(base_dir)):\n",
        "        cls_path = os.path.join(base_dir, cls)\n",
        "        if not os.path.isdir(cls_path):\n",
        "            continue\n",
        "\n",
        "        # limitar muestras por clase (para rapidez)\n",
        "        img_files = [\n",
        "            f for f in os.listdir(cls_path)\n",
        "            if f.lower().endswith(('.png', '.jpg', '.jpeg'))\n",
        "        ][:sample_per_class]\n",
        "\n",
        "        for fname in img_files:\n",
        "            img_path = os.path.join(cls_path, fname)\n",
        "            img = cv2.imread(img_path)\n",
        "            if img is None:\n",
        "                continue\n",
        "            h, w = img.shape[:2]\n",
        "            widths.append(w)\n",
        "            heights.append(h)\n",
        "\n",
        "    # --- Estadísticas ---\n",
        "    print(f\"Total de imágenes analizadas: {len(widths)}\")\n",
        "    print(f\"• Ancho promedio:  {np.mean(widths):.1f}px | Rango: {min(widths)}–{max(widths)}\")\n",
        "    print(f\"• Alto  promedio:  {np.mean(heights):.1f}px | Rango: {min(heights)}–{max(heights)}\")\n",
        "\n",
        "    # --- Subplots ---\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(10, 4))\n",
        "\n",
        "    axes[0].hist(widths, bins=20, color=\"#4B9CD3\", edgecolor='black', alpha=0.8)\n",
        "    axes[0].set_title(\"a) Distribución de anchos\")\n",
        "    axes[0].set_xlabel(\"Ancho (px)\")\n",
        "    axes[0].set_ylabel(\"Frecuencia\")\n",
        "\n",
        "    axes[1].hist(heights, bins=20, color=\"#E69138\", edgecolor='black', alpha=0.8)\n",
        "    axes[1].set_title(\"b) Distribución de altos\")\n",
        "    axes[1].set_xlabel(\"Alto (px)\")\n",
        "    axes[1].set_ylabel(\"Frecuencia\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Ejecutar función\n",
        "plot_image_size_distribution(base_dir)\n"
      ],
      "metadata": {
        "id": "w4WaSOEMmBHP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualización de Data Augmentation\n",
        "\n",
        "En esta sección se muestran ejemplos ilustrativos de las transformaciones de data augmentation implementadas dentro del modelo. Estas operaciones —como volteo horizontal, rotación, zoom y ajuste de contraste— permiten aumentar la variabilidad del conjunto de entrenamiento, ayudando al modelo a generalizar mejor y evitar el sobreajuste."
      ],
      "metadata": {
        "id": "Ep3qjRvOovoh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================================\n",
        "# VISUALIZACIÓN DEL DATA AUGMENTATION (EJEMPLOS ILUSTRATIVOS)\n",
        "# ==========================================================\n",
        "def visualize_data_augmentation(base_dir: str, image_size=(224,224)):\n",
        "    \"\"\"\n",
        "    Muestra una grilla con una imagen original y las transformaciones de\n",
        "    data augmentation aplicadas (flip, rotación, zoom, contraste)\n",
        "    para cada clase.\n",
        "    \"\"\"\n",
        "\n",
        "    # Capas de augmentación (idénticas a las del modelo)\n",
        "    aug_flip = tf.keras.layers.RandomFlip(\"horizontal\")\n",
        "    aug_rotation = tf.keras.layers.RandomRotation(0.08)\n",
        "    aug_zoom = tf.keras.layers.RandomZoom(0.1)\n",
        "    aug_contrast = tf.keras.layers.RandomContrast(0.2)\n",
        "\n",
        "    transformations = [\n",
        "        (\"Original\", lambda x: x),\n",
        "        (\"Flip\", aug_flip),\n",
        "        (\"Rotación\", aug_rotation),\n",
        "        (\"Zoom\", aug_zoom),\n",
        "        (\"Contraste\", aug_contrast),\n",
        "    ]\n",
        "\n",
        "    # Clases ordenadas\n",
        "    class_names = sorted([\n",
        "        d for d in os.listdir(base_dir)\n",
        "        if os.path.isdir(os.path.join(base_dir, d))\n",
        "    ])\n",
        "\n",
        "    n_rows = len(class_names)\n",
        "    n_cols = len(transformations)\n",
        "\n",
        "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(3.5*n_cols, 3.5*n_rows))\n",
        "    if n_rows == 1:\n",
        "        axes = np.expand_dims(axes, axis=0)  # asegura 2D\n",
        "\n",
        "    for i, cls in enumerate(class_names):\n",
        "        # Seleccionar una imagen aleatoria\n",
        "        cls_path = os.path.join(base_dir, cls)\n",
        "        candidates = [f for f in os.listdir(cls_path) if f.lower().endswith(('.png','.jpg','.jpeg'))]\n",
        "        if not candidates:\n",
        "            continue\n",
        "        img_path = os.path.join(cls_path, random.choice(candidates))\n",
        "\n",
        "        # Cargar y preparar la imagen\n",
        "        img = tf.keras.utils.load_img(img_path, target_size=image_size)\n",
        "        img_array = tf.keras.utils.img_to_array(img)\n",
        "        img_array = np.array(img_array, dtype=np.float32) / 255.0\n",
        "        img_batch = tf.expand_dims(img_array, 0)\n",
        "\n",
        "        for j, (name, transform) in enumerate(transformations):\n",
        "            ax = axes[i, j]\n",
        "            if name == \"Original\":\n",
        "                aug_img = img_array\n",
        "            else:\n",
        "                aug_img = transform(img_batch, training=True)[0].numpy().astype(np.float32)\n",
        "\n",
        "            ax.imshow(np.clip(aug_img, 0, 1))\n",
        "            if i == 0:\n",
        "                ax.set_title(name, fontsize=12, fontweight='bold')\n",
        "            if j == 0:\n",
        "                ax.set_ylabel(cls.capitalize(), fontsize=12, rotation=0, labelpad=60)\n",
        "            ax.axis(\"off\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Ejecutar\n",
        "visualize_data_augmentation(base_dir, image_size=(image_size[0], image_size[1]))"
      ],
      "metadata": {
        "id": "uDvO1Exeyn1r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Relación entre resolución y categoría\n",
        "\n",
        "Para analizar si existen diferencias notables en las **dimensiones originales** de las imágenes entre las categorías del dataset,  \n",
        "se generan dos **diagramas de caja (boxplots)** que muestran la dispersión de los valores de **ancho** y **alto** por clase.\n",
        "\n",
        "El objetivo de este análisis es verificar si alguna clase contiene imágenes sistemáticamente más pequeñas o más grandes,  \n",
        "lo cual podría influir en la calidad de la información visual antes de aplicar la etapa de *resizing*.\n",
        "\n"
      ],
      "metadata": {
        "id": "iRGy3CbxsLHR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================================\n",
        "# BOXPLOTS DE ANCHO Y ALTO POR CLASE\n",
        "# ==========================================================\n",
        "def plot_boxplots_dimensions(base_dir: str, sample_per_class: int = 1000):\n",
        "    \"\"\"\n",
        "    Genera dos boxplots: uno para la distribución de anchos y otro\n",
        "    para la de altos por clase.\n",
        "    \"\"\"\n",
        "    records = []\n",
        "\n",
        "    for cls in sorted(os.listdir(base_dir)):\n",
        "        cls_path = os.path.join(base_dir, cls)\n",
        "        if not os.path.isdir(cls_path):\n",
        "            continue\n",
        "\n",
        "        img_files = [\n",
        "            f for f in os.listdir(cls_path)\n",
        "            if f.lower().endswith(('.png', '.jpg', '.jpeg'))\n",
        "        ][:sample_per_class]\n",
        "\n",
        "        for fname in img_files:\n",
        "            img_path = os.path.join(cls_path, fname)\n",
        "            img = cv2.imread(img_path)\n",
        "            if img is None:\n",
        "                continue\n",
        "            h, w = img.shape[:2]\n",
        "            records.append({\"Clase\": cls, \"Ancho\": w, \"Alto\": h})\n",
        "\n",
        "    df = pd.DataFrame(records)\n",
        "\n",
        "    # --- Crear figura con dos subplots ---\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
        "\n",
        "    # Boxplot de anchos\n",
        "    sns.boxplot(data=df, x=\"Clase\", y=\"Ancho\", ax=axes[0], hue=\"Clase\", legend=False, palette=\"pastel\")\n",
        "    axes[0].set_title(\"a) Distribución de anchos\")\n",
        "    axes[0].set_xlabel(\"Clase\")\n",
        "    axes[0].set_ylabel(\"Ancho (px)\")\n",
        "    axes[0].grid(axis='y', linestyle='--', alpha=0.6)\n",
        "\n",
        "    # Boxplot de altos\n",
        "    sns.boxplot(data=df, x=\"Clase\", y=\"Alto\", ax=axes[1], hue=\"Clase\", legend=False, palette=\"pastel\")\n",
        "    axes[1].set_title(\"b) Distribución de altos\")\n",
        "    axes[1].set_xlabel(\"Clase\")\n",
        "    axes[1].set_ylabel(\"Alto (px)\")\n",
        "    axes[1].grid(axis='y', linestyle='--', alpha=0.6)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Ejecutar\n",
        "plot_boxplots_dimensions(base_dir)\n"
      ],
      "metadata": {
        "id": "UrITpC0RsTHe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Promedio de intensidad o luminosidad\n",
        "\n",
        "A continuación, se analiza la **luminosidad promedio de cada imagen**. Este indicador permite observar el rango de brillo del dataset y justificar el uso de normalización (`Rescaling(1./255)`) en el modelo.  \n",
        "\n",
        "Un dataset con alto contraste o valores de brillo muy variables puede beneficiar de técnicas de normalización.\n"
      ],
      "metadata": {
        "id": "2ZpwtFDotPwL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================================\n",
        "# HISTOGRAMA DE BRILLO PROMEDIO (LUMINOSIDAD)\n",
        "# ==========================================================\n",
        "def plot_brightness_distribution(base_dir: str, sample_per_class: int = 1000):\n",
        "    brightness = []\n",
        "    labels = []\n",
        "\n",
        "    for cls in sorted(os.listdir(base_dir)):\n",
        "        cls_path = os.path.join(base_dir, cls)\n",
        "        if not os.path.isdir(cls_path):\n",
        "            continue\n",
        "\n",
        "        img_files = [\n",
        "            f for f in os.listdir(cls_path)\n",
        "            if f.lower().endswith(('.png', '.jpg', '.jpeg'))\n",
        "        ][:sample_per_class]\n",
        "\n",
        "        for fname in img_files:\n",
        "            img_path = os.path.join(cls_path, fname)\n",
        "            img = cv2.imread(img_path)\n",
        "            if img is None:\n",
        "                continue\n",
        "            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "            brightness.append(np.mean(gray))\n",
        "            labels.append(cls)\n",
        "\n",
        "    df = pd.DataFrame({\"Clase\": labels, \"Brillo promedio\": brightness})\n",
        "\n",
        "    plt.figure(figsize=(7,5))\n",
        "    sns.histplot(data=df, x=\"Brillo promedio\", hue=\"Clase\", bins=30, kde=True, palette=\"Set2\")\n",
        "    plt.xlabel(\"Nivel de brillo (0–255)\")\n",
        "    plt.ylabel(\"Frecuencia\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Ejecutar\n",
        "plot_brightness_distribution(base_dir)\n"
      ],
      "metadata": {
        "id": "MWjvZf4SsYCk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Distribución de color (histogramas RGB)\n",
        "\n",
        "Por último, se presenta un análisis ilustrativo de la **distribución de color** en el dataset. Para cada clase, se toma una imagen representativa y se grafican los **histogramas de los canales rojo, verde y azul (RGB)**.  \n",
        "\n",
        "Esto permite observar diferencias visuales generales y validar que las imágenes estén en formato a color.\n"
      ],
      "metadata": {
        "id": "kt4bpgNgteXM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================================\n",
        "# HISTOGRAMAS DE COLOR (RGB) POR CLASE\n",
        "# ==========================================================\n",
        "def plot_color_histograms(base_dir: str, image_size=(224,224)):\n",
        "    class_names = sorted([\n",
        "        d for d in os.listdir(base_dir)\n",
        "        if os.path.isdir(os.path.join(base_dir, d))\n",
        "    ])\n",
        "\n",
        "    fig, axes = plt.subplots(len(class_names), 2, figsize=(10, 4*len(class_names)))\n",
        "\n",
        "    for i, cls in enumerate(class_names):\n",
        "        cls_path = os.path.join(base_dir, cls)\n",
        "        img_files = [f for f in os.listdir(cls_path) if f.lower().endswith(('.png','.jpg','.jpeg'))]\n",
        "        if not img_files:\n",
        "            continue\n",
        "\n",
        "        img_path = os.path.join(cls_path, random.choice(img_files))\n",
        "        img = cv2.imread(img_path)\n",
        "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        img_rgb = cv2.resize(img_rgb, image_size)\n",
        "\n",
        "        # --- Mostrar imagen ---\n",
        "        axes[i,0].imshow(img_rgb)\n",
        "        axes[i,0].set_title(f\"{cls.capitalize()} (ejemplo)\")\n",
        "        axes[i,0].axis(\"off\")\n",
        "\n",
        "        # --- Histograma RGB ---\n",
        "        colors = ('r', 'g', 'b')\n",
        "        for j, col in enumerate(colors):\n",
        "            hist = cv2.calcHist([img_rgb], [j], None, [256], [0,256])\n",
        "            axes[i,1].plot(hist, color=col)\n",
        "        axes[i,1].set_title(\"Histograma RGB\")\n",
        "        axes[i,1].set_xlabel(\"Nivel de intensidad\")\n",
        "        axes[i,1].set_ylabel(\"Frecuencia\")\n",
        "        axes[i,1].set_xlim([0,256])\n",
        "        axes[i,1].grid(alpha=0.3)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Ejecutar\n",
        "plot_color_histograms(base_dir, image_size=(image_size[0], image_size[1]))"
      ],
      "metadata": {
        "id": "B1uPyho3scW6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## División train/validation/test\n",
        "\n",
        "Para evaluar correctamente la capacidad de generalización del modelo,\n",
        "se divide el conjunto de datos en tres subconjuntos independientes: **70 % para entrenamiento, 20 % para validación y 10 % para prueba.**"
      ],
      "metadata": {
        "id": "G1zW4EXCvFLW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================================\n",
        "# TRAIN-VAL-TEST DIVISION (70-20-10)\n",
        "# ==========================================================\n",
        "def traint_val_test_split(base_dir:str, split_dir:str):\n",
        "    # Crear carpetas destino\n",
        "    for split in ['train', 'val', 'test']:\n",
        "        for cls in os.listdir(base_dir):\n",
        "            os.makedirs(os.path.join(split_dir, split, cls), exist_ok=True)\n",
        "\n",
        "    # Ratios\n",
        "    train_ratio = 0.7\n",
        "    val_ratio = 0.2\n",
        "    test_ratio = 0.1\n",
        "\n",
        "    # Procesar cada clase\n",
        "    for cls in os.listdir(base_dir):\n",
        "        cls_path = os.path.join(base_dir, cls)\n",
        "        images = [f for f in os.listdir(cls_path) if f.lower().endswith(('.png','.jpg','.jpeg'))]\n",
        "\n",
        "        # Dividir train / val / test\n",
        "        train_files, temp_files = train_test_split(images, test_size=(1-train_ratio), random_state=seed)\n",
        "        val_size = val_ratio / (val_ratio + test_ratio)\n",
        "        val_files, test_files = train_test_split(temp_files, test_size=(1-val_size), random_state=seed)\n",
        "\n",
        "        # Copiar archivos\n",
        "        for fname in train_files:\n",
        "            shutil.copy(os.path.join(cls_path, fname), os.path.join(split_dir, 'train', cls, fname))\n",
        "        for fname in val_files:\n",
        "            shutil.copy(os.path.join(cls_path, fname), os.path.join(split_dir, 'val', cls, fname))\n",
        "        for fname in test_files:\n",
        "            shutil.copy(os.path.join(cls_path, fname), os.path.join(split_dir, 'test', cls, fname))\n",
        "\n",
        "    print(\"División completada con semilla =\", seed)\n",
        "    print(\"Estructura creada en:\", split_dir)\n",
        "\n",
        "    for split in ['train', 'val', 'test']:\n",
        "        print(f\"\\n * {split.upper()}\")\n",
        "        for cls in os.listdir(os.path.join(split_dir, split)):\n",
        "            count = len(os.listdir(os.path.join(split_dir, split, cls)))\n",
        "            print(f\"  {cls}: {count} imágenes\")\n",
        "\n",
        "\n",
        "# Ejecutar división solo una vez\n",
        "traint_val_test_split(base_dir, split_dir)\n",
        "\n",
        "# ==========================================================\n",
        "# CARGA DE LOS DATASETS\n",
        "# ==========================================================\n",
        "train_ds_raw = tf.keras.utils.image_dataset_from_directory(\n",
        "    f\"{split_dir}/train\",\n",
        "    image_size=image_size,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    seed=seed\n",
        ")\n",
        "\n",
        "val_ds_raw = tf.keras.utils.image_dataset_from_directory(\n",
        "    f\"{split_dir}/val\",\n",
        "    image_size=image_size,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    seed=seed\n",
        ")\n",
        "\n",
        "test_ds_raw = tf.keras.utils.image_dataset_from_directory(\n",
        "    f\"{split_dir}/test\",\n",
        "    image_size=image_size,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,\n",
        "    seed=seed\n",
        ")\n",
        "\n",
        "# Guarda los nombres de clase ANTES de optimizar los datasets\n",
        "class_names = test_ds_raw.class_names\n",
        "print(\"Clases detectadas:\", class_names)\n",
        "\n",
        "# ==========================================================\n",
        "# OPTIMIZACIÓN DE LOS DATASETS\n",
        "# ==========================================================\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "def prepare_dataset(ds, shuffle=False):\n",
        "    if shuffle:\n",
        "        ds = ds.shuffle(buffer_size=1000)\n",
        "    ds = ds.prefetch(AUTOTUNE)\n",
        "    return ds\n",
        "\n",
        "train_ds = prepare_dataset(train_ds_raw, shuffle=True)\n",
        "val_ds   = prepare_dataset(val_ds_raw)\n",
        "test_ds  = prepare_dataset(test_ds_raw)\n",
        "\n",
        "print(\"Datasets listos y optimizados para entrenamiento.\")"
      ],
      "metadata": {
        "id": "cEMADKmdWuvX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Arquitectura, configuración y entrenamiento del modelo\n",
        "\n",
        "### Definición del modelo\n",
        "\n",
        "El modelo propuesto se basa en una arquitectura tipo **EfficientNet**, adaptada específicamente para imágenes de resonancias magnéticas (MRI).  \n",
        "Se compone de los siguientes bloques principales:\n",
        "\n",
        "- **Activación Mish:** una función suave y no monótona que mejora la propagación de gradientes respecto a ReLU.  \n",
        "- **Bloques MBConv mejorados:** cada bloque incluye expansión, convolución separable en profundidad (*Depthwise Separable Conv*),  \n",
        "  módulo *Squeeze-and-Excitation (SE)* para recalibración de canales, y *DropConnect* para regularización.  \n",
        "- **Data Augmentation integrado:** las transformaciones (flip, rotación, zoom, contraste) se aplican dinámicamente solo durante el entrenamiento.  \n",
        "- **Head final:** una capa *Conv2D* de proyección a 1280 filtros, *Global Average Pooling*, *Dropout (0.4)* y salida *softmax* para las cuatro clases.\n",
        "\n",
        "El diseño prioriza un equilibrio entre **precisión y eficiencia computacional**, aprovechando el aprendizaje jerárquico de las capas convolucionales profundas sin requerir preentrenamiento.\n"
      ],
      "metadata": {
        "id": "ZvlNl8u8vcSu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================================\n",
        "# ACTIVACIÓN MISH\n",
        "# ==========================================================\n",
        "@tf.keras.utils.register_keras_serializable()\n",
        "def mish(x):\n",
        "    return x * tf.math.tanh(tf.math.softplus(x))\n",
        "\n",
        "\n",
        "# ==========================================================\n",
        "# BLOQUE MBConv MEJORADO (con DropConnect)\n",
        "# ==========================================================\n",
        "def MBConvMRI(inputs, out_channels, expand_ratio, stride, se_ratio=0.25, drop_rate=0.2):\n",
        "    in_channels = inputs.shape[-1]\n",
        "    shortcut = inputs\n",
        "    x = inputs\n",
        "\n",
        "    expanded = int(in_channels * expand_ratio)\n",
        "    if expand_ratio != 1:\n",
        "        x = layers.Conv2D(expanded, 1, padding='same', use_bias=False, kernel_initializer=HeNormal())(x)\n",
        "        x = layers.BatchNormalization()(x)\n",
        "        x = layers.Activation(mish)(x)\n",
        "\n",
        "    # Depthwise separable\n",
        "    x = layers.DepthwiseConv2D(3, strides=stride, padding='same', use_bias=False)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation(mish)(x)\n",
        "\n",
        "    # Squeeze and Excitation\n",
        "    se = layers.GlobalAveragePooling2D()(x)\n",
        "    se = layers.Reshape((1,1,expanded))(se)\n",
        "    se = layers.Conv2D(int(expanded * se_ratio), 1, activation=mish, padding='same')(se)\n",
        "    se = layers.Conv2D(expanded, 1, activation='sigmoid', padding='same')(se)\n",
        "    x = layers.Multiply()([x, se])\n",
        "\n",
        "    # Proyección\n",
        "    x = layers.Conv2D(out_channels, 1, padding='same', use_bias=False, kernel_initializer=HeNormal())(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "\n",
        "    # Residual con DropConnect\n",
        "    if stride == 1 and in_channels == out_channels:\n",
        "        if drop_rate > 0:\n",
        "            x = layers.Dropout(drop_rate)(x)\n",
        "        x = layers.Add()([x, shortcut])\n",
        "    return x\n",
        "\n",
        "\n",
        "# ==========================================================\n",
        "# MODELO EfficientMRI-Net v2\n",
        "# ==========================================================\n",
        "def build_efficient_mri_net_v2(num_classes=4, input_shape=(image_size[0], image_size[1], 3)):\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "\n",
        "    # -----------------------------\n",
        "    # Data augmentation integrado\n",
        "    # -----------------------------\n",
        "    x = layers.RandomFlip(\"horizontal\")(inputs)\n",
        "    x = layers.RandomRotation(0.08)(x)\n",
        "    x = layers.RandomZoom(0.1)(x)\n",
        "    x = layers.RandomContrast(0.2)(x)\n",
        "    x = layers.Rescaling(1./255)(x)\n",
        "\n",
        "    # -----------------------------\n",
        "    # Bloque inicial\n",
        "    # -----------------------------\n",
        "    x = layers.Conv2D(48, 3, strides=2, padding='same', use_bias=False, kernel_initializer=HeNormal())(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation(mish)(x)\n",
        "\n",
        "    # -----------------------------\n",
        "    # Bloques MBConv\n",
        "    # -----------------------------\n",
        "    x = MBConvMRI(x, 16, 1, 1, drop_rate=0.1)\n",
        "    x = MBConvMRI(x, 24, 3, 2, drop_rate=0.1)\n",
        "    x = MBConvMRI(x, 24, 3, 1, drop_rate=0.1)\n",
        "    x = MBConvMRI(x, 40, 4, 2, drop_rate=0.15)\n",
        "    x = MBConvMRI(x, 40, 4, 1, drop_rate=0.15)\n",
        "    x = MBConvMRI(x, 80, 4, 2, drop_rate=0.2)\n",
        "    x = MBConvMRI(x, 80, 4, 1, drop_rate=0.2)\n",
        "    x = MBConvMRI(x, 112, 4, 1, drop_rate=0.25)\n",
        "    x = MBConvMRI(x, 160, 4, 2, drop_rate=0.25)\n",
        "    x = MBConvMRI(x, 320, 4, 1, drop_rate=0.3)\n",
        "\n",
        "    # -----------------------------\n",
        "    # Head final\n",
        "    # -----------------------------\n",
        "    x = layers.Conv2D(1280, 1, padding='same', use_bias=False, kernel_initializer=HeNormal())(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation(mish)(x)\n",
        "\n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "    x = layers.Dropout(0.4)(x)\n",
        "    outputs = layers.Dense(num_classes, activation='softmax', dtype='float32')(x)\n",
        "\n",
        "    model = Model(inputs, outputs, name=\"EfficientMRI_Net_v2\")\n",
        "    return model\n",
        "\n",
        "\n",
        "#Crea el modelo\n",
        "model = build_efficient_mri_net_v2(num_classes=4, input_shape=(image_size[0], image_size[1],3))\n",
        "model.summary()\n"
      ],
      "metadata": {
        "id": "1RFM0cWSMCpZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Compilación del modelo\n",
        "\n",
        "Una vez definida la arquitectura, el modelo se compila especificando los hiperparámetros de entrenamiento más importantes:\n",
        "\n",
        "- **Optimizador:** se emplea `AdamW`, una variante del optimizador Adam que incluye *decaimiento de pesos (weight decay)* para mejorar la generalización y reducir el sobreajuste.  \n",
        "- **Tasa de aprendizaje (learning rate):** se inicia en $8 \\times 10^{-4}$, valor determinado experimentalmente para equilibrar la velocidad de convergencia y la estabilidad del entrenamiento.  \n",
        "- **Función de pérdida:** `SparseCategoricalCrossentropy`, adecuada para clasificación multiclase con etiquetas enteras.  \n",
        "- **Métrica de desempeño:** `accuracy`, que permite evaluar la proporción de aciertos sobre el total de predicciones.\n",
        "\n",
        "Esta configuración busca un entrenamiento estable, con regularización implícita y una métrica interpretativa para comparar resultados entre modelos.\n"
      ],
      "metadata": {
        "id": "ACRSQX-mxtHh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================================\n",
        "# COMPILACIÓN\n",
        "# ==========================================================\n",
        "optimizer = AdamW(learning_rate=8e-4, weight_decay=1e-5)\n",
        "loss_fn = SparseCategoricalCrossentropy()\n",
        "\n",
        "model.compile(\n",
        "    optimizer=optimizer,\n",
        "    loss=loss_fn,\n",
        "    metrics=['accuracy']\n",
        ")\n"
      ],
      "metadata": {
        "id": "-sM0cyJDw2X4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Configuración de Callbacks\n",
        "\n",
        "Durante el entrenamiento se emplean diferentes *callbacks* que permiten optimizar el proceso y evitar el sobreajuste:\n",
        "\n",
        "- **EarlyStopping:** detiene el entrenamiento cuando la pérdida de validación no mejora tras varias épocas consecutivas (paciencia = 6).  \n",
        "- **ReduceLROnPlateau:** reduce automáticamente la tasa de aprendizaje en un factor de 0.6 cuando la validación se estanca (paciencia = 5).  \n",
        "- **ModelCheckpoint:** guarda los pesos del modelo con la mayor exactitud de validación alcanzada durante el entrenamiento.\n",
        "- **LrLogger:** registra y muestra el valor actualizado del learning rate al final de cada época, facilitando el seguimiento del ajuste dinámico de la tasa de aprendizaje.\n",
        "\n",
        "El uso conjunto de estos mecanismos asegura una mejor generalización del modelo y evita un entrenamiento excesivo o ineficiente.\n",
        "\n"
      ],
      "metadata": {
        "id": "W1Qy_HfjyVKt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================================\n",
        "# CALLBACKS\n",
        "# ==========================================================\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.6, patience=5, min_lr=1e-5, verbose=1)\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=6, restore_best_weights=True, verbose=1)\n",
        "checkpoint = ModelCheckpoint('EfficientMRI_Net_v2.keras', monitor='val_accuracy', save_best_only=True, verbose=1)\n",
        "\n",
        "\n",
        "# ==========================================================\n",
        "# CALLBACK ADICIONAL: REGISTRO DEL LEARNING RATE\n",
        "# ==========================================================\n",
        "class LrLogger(tf.keras.callbacks.Callback):\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        logs = logs or {}\n",
        "        # Guarda el valor actual del learning rate\n",
        "        logs['lr'] = float(tf.keras.backend.get_value(self.model.optimizer.lr))\n",
        "        print(f\"Epoch {epoch+1}: Learning Rate = {logs['lr']:.6f}\")\n",
        "\n",
        "# Añadir a la lista de callbacks\n",
        "callbacks = [reduce_lr, early_stop, checkpoint, LrLogger()]\n",
        "print(\"Callbacks configurados con registro de learning rate.\")\n"
      ],
      "metadata": {
        "id": "znpRtL1ex7_U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Entrenamiento del modelo y evolución del learning rate\n",
        "\n",
        "El modelo se entrena durante un máximo de 80 épocas, con un tamaño de lote definido por `batch_size`. Los *callbacks* permiten ajustar automáticamente la tasa de aprendizaje (`ReduceLROnPlateau`) y detener el entrenamiento cuando no se observa mejora en la validación (`EarlyStopping`)."
      ],
      "metadata": {
        "id": "uHQdWx0ZzSUk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================================\n",
        "# ENTRENAMIENTO O CARGA DEL MODELO\n",
        "# ==========================================================\n",
        "history = model.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=80,\n",
        "    batch_size=batch_size,\n",
        "    callbacks=callbacks,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# ==========================================================\n",
        "# GUARDA LA HISTORIA\n",
        "# ==========================================================\n",
        "# Guardar la historia completa como JSON\n",
        "with open('history_efficient_mri_net_v2.json', 'w') as f:\n",
        "        json.dump(history.history, f)"
      ],
      "metadata": {
        "id": "H7NkJQ5byv6q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evolución del entrenamiento y del Learning Rate\n",
        "\n",
        "Se presenta:\n",
        "\n",
        "- **(a)** La precisión (accuracy) aumenta\n",
        "progresivamente hasta estabilizarse.  \n",
        "- **(b)** La pérdida (loss) disminuye de manera consistente, reflejando un aprendizaje estable.  \n",
        "- **(c)** La curva del *learning rate* muestra los ajustes automáticos aplicados por el callback `ReduceLROnPlateau`,  \n",
        "  reduciendo la tasa cuando el modelo deja de mejorar en la validación.\n",
        "\n",
        "Este comportamiento indica un entrenamiento controlado, sin sobreajuste evidente y con capacidad de adaptación en la tasa de aprendizaje.\n"
      ],
      "metadata": {
        "id": "jDqpODPQ0IsI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================================\n",
        "# GRÁFICAS DE ENTRENAMIENTO, VALIDACIÓN Y LEARNING RATE\n",
        "# ==========================================================\n",
        "acc = history.history.get('accuracy', [])\n",
        "val_acc = history.history.get('val_accuracy', [])\n",
        "loss = history.history.get('loss', [])\n",
        "val_loss = history.history.get('val_loss', [])\n",
        "lr = history.history.get('lr', [])\n",
        "\n",
        "epochs_range = range(1, len(acc) + 1)\n",
        "\n",
        "fig, axes = plt.subplots(1, 3, figsize=(16, 4))\n",
        "fig.suptitle(\"Figura X. Evolución del entrenamiento y del Learning Rate\", fontsize=14, y=1.03)\n",
        "\n",
        "# ----------------------------------------------------------\n",
        "# Accuracy\n",
        "# ----------------------------------------------------------\n",
        "axes[0].plot(epochs_range, acc, 'b-', label='Entrenamiento')\n",
        "axes[0].plot(epochs_range, val_acc, 'r--', label='Validación')\n",
        "axes[0].set_title('a) Precisión (Accuracy)')\n",
        "axes[0].set_xlabel('Época')\n",
        "axes[0].set_ylabel('Accuracy')\n",
        "axes[0].legend()\n",
        "axes[0].grid(True, linestyle='--', alpha=0.5)\n",
        "\n",
        "# ----------------------------------------------------------\n",
        "# Loss\n",
        "# ----------------------------------------------------------\n",
        "axes[1].plot(epochs_range, loss, 'b-', label='Entrenamiento')\n",
        "axes[1].plot(epochs_range, val_loss, 'r--', label='Validación')\n",
        "axes[1].set_title('b) Pérdida (Loss)')\n",
        "axes[1].set_xlabel('Época')\n",
        "axes[1].set_ylabel('Loss')\n",
        "axes[1].legend()\n",
        "axes[1].grid(True, linestyle='--', alpha=0.5)\n",
        "\n",
        "# ----------------------------------------------------------\n",
        "# Learning Rate\n",
        "# ----------------------------------------------------------\n",
        "if lr and len(lr) == len(acc):\n",
        "    axes[2].plot(epochs_range, lr, color='orange', linewidth=2)\n",
        "    axes[2].set_title('c) Evolución del Learning Rate')\n",
        "    axes[2].set_xlabel('Época')\n",
        "    axes[2].set_ylabel('Learning Rate')\n",
        "    axes[2].grid(True, linestyle='--', alpha=0.5)\n",
        "else:\n",
        "    axes[2].text(0.5, 0.5, \"LR no registrado\", ha='center', va='center', fontsize=12)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ZXCxjlIGswxh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluación final del modelo\n",
        "\n",
        "El modelo se evalúa sobre el conjunto de prueba, que contiene imágenes nunca vistas durante el entrenamiento. Esta etapa permite medir la **capacidad de generalización** del modelo y analizar su desempeño tanto global como por clase."
      ],
      "metadata": {
        "id": "fftdUcgW1AVp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================================\n",
        "# EVALUACIÓN FINAL EN TEST\n",
        "# ==========================================================\n",
        "test_loss, test_acc = model.evaluate(test_ds, verbose=1)\n",
        "print(f\"\\nTest Accuracy: {test_acc:.4f}\")\n",
        "print(f\"Test Loss: {test_loss:.4f}\")\n"
      ],
      "metadata": {
        "id": "qyWjcRYaRmUm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Matriz de confusión\n",
        "\n",
        "En esta sección se evalúa el desempeño final del modelo EfficientMRI-Net v2 sobre el conjunto de prueba.\n",
        "Se genera el reporte de clasificación, que incluye métricas clave como precisión, recuperación (recall) y F1-score para cada clase, permitiendo analizar el comportamiento individual del modelo frente a cada tipo de tumor.\n",
        "\n",
        "Además, se construye la matriz de confusión —tanto en valores absolutos como normalizados— para visualizar la relación entre las predicciones y las etiquetas reales, facilitando la detección de posibles confusiones entre clases y la interpretación global del rendimiento del modelo."
      ],
      "metadata": {
        "id": "azjNCFoo1pA6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================================\n",
        "# MATRIZ DE CONFUSIÓN Y REPORTE DE CLASIFICACIÓN\n",
        "# ==========================================================\n",
        "\n",
        "# Obtener etiquetas reales y predicciones\n",
        "y_true = np.concatenate([y for x, y in test_ds], axis=0).astype(int)\n",
        "y_pred_probs = model.predict(test_ds)\n",
        "y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "\n",
        "# ----------------------------------------------------------\n",
        "# Reporte de clasificación\n",
        "# ----------------------------------------------------------\n",
        "print(\"\\nReporte de Clasificación - EfficientMRI-Net v2\\n\")\n",
        "print(classification_report(y_true, y_pred, target_names=class_names, digits=3))\n",
        "\n",
        "# ----------------------------------------------------------\n",
        "# Matriz de confusión\n",
        "# ----------------------------------------------------------\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "# Crear DataFrame para visualización o exportación\n",
        "cm_df = pd.DataFrame(cm, index=class_names, columns=class_names)\n",
        "display(cm_df)\n",
        "\n",
        "# ----------------------------------------------------------\n",
        "# Gráfica de la matriz (valores absolutos)\n",
        "# ----------------------------------------------------------\n",
        "plt.figure(figsize=(7,6))\n",
        "sns.heatmap(cm_df, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
        "plt.xlabel(\"Predicción\")\n",
        "plt.ylabel(\"Etiqueta Real\")\n",
        "plt.xticks(rotation=45)\n",
        "plt.yticks(rotation=0)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# ----------------------------------------------------------\n",
        "# Versión normalizada (% por fila)\n",
        "# ----------------------------------------------------------\n",
        "cm_norm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "cm_norm_df = pd.DataFrame(np.round(cm_norm*100, 2), index=class_names, columns=class_names)\n",
        "\n",
        "plt.figure(figsize=(7,6))\n",
        "sns.heatmap(cm_norm_df, annot=True, fmt='.2f', cmap='Greens', cbar=False)\n",
        "plt.xlabel(\"Predicción\")\n",
        "plt.ylabel(\"Etiqueta Real\")\n",
        "plt.xticks(rotation=45)\n",
        "plt.yticks(rotation=0)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "DCjLoldKSyVW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cálculo del AUC multiclase\n",
        "\n",
        "En esta sección se calcula el Área Bajo la Curva (AUC) para evaluar la capacidad del modelo EfficientMRI-Net v2 de distinguir correctamente entre las distintas clases de tumores.\n",
        "Se obtiene el AUC individual por clase y los promedios macro y ponderado, que ofrecen una visión global del rendimiento del modelo sin y con consideración del balance de clases, respectivamente."
      ],
      "metadata": {
        "id": "Rq8yhpsa4M8a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================================\n",
        "# CÁLCULO DETALLADO DEL AUC MULTICLASE\n",
        "# ==========================================================\n",
        "\n",
        "# Convertir etiquetas verdaderas a formato binarizado (one-hot)\n",
        "y_true_bin = label_binarize(y_true, classes=np.arange(len(class_names)))\n",
        "\n",
        "# ----------------------------------------------------------\n",
        "# AUC por clase\n",
        "# ----------------------------------------------------------\n",
        "auc_scores = {}\n",
        "for i, class_name in enumerate(class_names):\n",
        "    try:\n",
        "        auc_value = roc_auc_score(y_true_bin[:, i], y_pred_probs[:, i])\n",
        "        auc_scores[class_name] = auc_value\n",
        "    except ValueError:\n",
        "        auc_scores[class_name] = np.nan  # por si alguna clase no aparece en test\n",
        "\n",
        "# ----------------------------------------------------------\n",
        "# AUC promedio (macro y ponderado)\n",
        "# ----------------------------------------------------------\n",
        "auc_macro = roc_auc_score(y_true_bin, y_pred_probs, multi_class='ovr', average='macro')\n",
        "auc_weighted = roc_auc_score(y_true_bin, y_pred_probs, multi_class='ovr', average='weighted')\n",
        "\n",
        "# ----------------------------------------------------------\n",
        "# Mostrar resultados en tabla\n",
        "# ----------------------------------------------------------\n",
        "df_auc = pd.DataFrame({\n",
        "    \"Clase\": list(auc_scores.keys()),\n",
        "    \"AUC por clase\": [round(v, 4) for v in auc_scores.values()]\n",
        "})\n",
        "df_auc.loc[len(df_auc)] = [\"Promedio (macro)\", round(auc_macro, 4)]\n",
        "df_auc.loc[len(df_auc)] = [\"Promedio (ponderado)\", round(auc_weighted, 4)]\n",
        "\n",
        "print(\"\\nResultados de AUC por clase y promedios:\\n\")\n",
        "display(df_auc)\n",
        "\n",
        "# ----------------------------------------------------------\n",
        "# Gráfico de barras de AUC\n",
        "# ----------------------------------------------------------\n",
        "plt.figure(figsize=(8,4))\n",
        "plt.bar(df_auc[\"Clase\"][:-2], df_auc[\"AUC por clase\"][:-2], color=\"#4B9CD3\")\n",
        "plt.axhline(auc_macro, color='orange', linestyle='--', label=f\"Macro Avg = {auc_macro:.3f}\")\n",
        "plt.axhline(auc_weighted, color='green', linestyle='--', label=f\"Weighted Avg = {auc_weighted:.3f}\")\n",
        "plt.title(\"Figura X. AUC por clase - EfficientMRI-Net v2\")\n",
        "plt.xlabel(\"Clase\")\n",
        "plt.ylabel(\"Área bajo la curva (AUC)\")\n",
        "plt.ylim(0, 1.05)\n",
        "plt.legend()\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.6)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "t5NQIyPT3XVi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Curvas ROC por clase (One-vs-Rest)\n",
        "En esta sección se grafican las curvas ROC (Receiver Operating Characteristic) para cada clase del modelo utilizando el enfoque one-vs-rest.\n",
        "Cada curva muestra la relación entre la tasa de verdaderos positivos (TPR) y la tasa de falsos positivos (FPR), permitiendo evaluar visualmente la capacidad discriminativa del modelo para cada categoría.\n",
        "El valor de AUC asociado a cada curva indica el nivel de desempeño: cuanto más cerca esté de 1, mejor es la separación entre clases."
      ],
      "metadata": {
        "id": "sFZsh-KR4XVK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================================\n",
        "# CURVAS ROC POR CLASE (ONE-VS-REST)\n",
        "# ==========================================================\n",
        "\n",
        "# Paleta de colores suave\n",
        "palette = sns.color_palette(\"Set2\", len(class_names))\n",
        "\n",
        "plt.figure(figsize=(8,6))\n",
        "for i, (cls, color) in enumerate(zip(class_names, palette)):\n",
        "    # Calcular curva ROC para cada clase\n",
        "    fpr, tpr, _ = roc_curve(y_true_bin[:, i], y_pred_probs[:, i])\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    plt.plot(fpr, tpr, lw=2, color=color, label=f\"{cls} (AUC = {roc_auc:.2f})\")\n",
        "\n",
        "# Línea diagonal de referencia\n",
        "plt.plot([0, 1], [0, 1], color='gray', lw=2, linestyle='--')\n",
        "\n",
        "# Ajustes de la figura\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel(\"Tasa de Falsos Positivos (FPR)\", fontsize=11)\n",
        "plt.ylabel(\"Tasa de Verdaderos Positivos (TPR)\", fontsize=11)\n",
        "plt.legend(loc=\"lower right\", frameon=True)\n",
        "plt.grid(alpha=0.4)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "fsKlWoqLr7Em"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kFPU7r7PC1Ld"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}